The data is theoretically created hence EDA is not performed.

# import sklearn packages
# Creating numpy arrays
# Saving list of array in .pkl file
# loading data
# Creating dataframe
# Declare feature vector and target variable
# Split into training and testing data
# First create the base model to tune
# Cross validation set
# Number of trees in random forest
# Number of features to consider at every split
# Maximum number of levels in tree
# Minimum number of samples required to split a node
# Minimum number of samples required at each leaf node
# Method of selecting samples for training each tree
# create random search
# search across 20 different combinations
# Fit the random search model
# Create the parameter grid based on the results of random search 
# Instantiate grid search
# fit grid
# evaluating the model
